# Authorship Attribution System Documentation

## 1. Overview

This authorship attribution system is designed to identify the source of AI-generated text by analyzing stylometric features and language patterns. The system can distinguish between text generated by different language models (e.g., GPT-4, Claude, LLaMA) by training classifiers on extracted stylometric features and transformer-based embeddings.

## 2. Installation

### Requirements
```
numpy
pandas
scikit-learn
transformers
matplotlib
seaborn
joblib
torch
nltk
```

### Setup
1. Clone the repository
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Create necessary directories:
   ```bash
   mkdir -p data/raw/gpt4 data/raw/claude data/raw/llama
   mkdir -p models/stylometric models/combined
   mkdir -p results/evaluation results/stylometric results/combined
   ```

## 3. Directory Structure

```
project/
├── data/
│   ├── raw/
│   │   ├── gpt4/           # GPT-4 generated text samples
│   │   ├── claude/         # Claude generated text samples
│   │   └── llama/          # LLaMA generated text samples
│   └── test_samples.csv    # Processed dataset from raw files
├── models/
│   ├── stylometric/        # Models trained on stylometric features
│   └── combined/           # Models trained on combined features
├── results/
│   ├── evaluation/         # Evaluation results
│   ├── stylometric/        # Results from stylometric models
│   └── combined/           # Results from combined feature models
└── src/
    ├── create_dataset.py   # Script to create dataset from raw files
    ├── create_sample_model.py # Script to create a sample model
    ├── data_loader.py      # Functions to load data
    ├── evaluate_model.py   # Script to evaluate models
    ├── extract_features.py # Script to extract features
    ├── feature_extractor.py # Feature extraction functions
    └── train_models.py     # Script to train multiple models
```

## 4. Files and Their Functions

### Core Files

| File | Purpose |
|------|---------|
| `src/create_dataset.py` | Creates a CSV dataset from raw text files in the data directory structure |
| `src/feature_extractor.py` | Contains functions to extract stylometric features and transformer embeddings |
| `src/create_sample_model.py` | Trains a simple Random Forest model on the dataset |
| `src/train_models.py` | Trains multiple classifiers and evaluates their performance |
| `src/evaluate_model.py` | Evaluates a trained model on new data |
| `src/data_loader.py` | Utility functions to load data from different sources |
| `src/extract_features.py` | Script to extract and save features separately |

## 5. Workflow and File Interactions

The system follows this workflow:

1. **Data Preparation**: `create_dataset.py` reads raw text files from the directory structure and creates a CSV dataset.

2. **Feature Extraction**: `feature_extractor.py` extracts stylometric features from the text, including:
   - Text length metrics
   - Punctuation usage patterns
   - Sentence structure characteristics
   - Lexical diversity measures
   - Capitalization patterns
   - Optionally, transformer-based embeddings from RoBERTa and XLNet models

3. **Model Training**: Either `create_sample_model.py` (for a quick single model) or `train_models.py` (for multiple models):
   - Loads the dataset
   - Extracts features
   - Splits the data into training and testing sets
   - Trains models (Logistic Regression, Random Forest, Neural Network)
   - Evaluates models and saves them to disk

4. **Model Evaluation**: `evaluate_model.py`:
   - Loads a trained model
   - Loads new data and extracts the same features
   - Makes predictions
   - Generates evaluation metrics (accuracy, confusion matrix, classification report)
   - Saves results to the output directory

## 6. Usage Instructions

### 6.1 Preparing the Dataset

1. Place your text samples in the appropriate directories:
   - `data/raw/gpt4/` - Text samples from GPT-4
   - `data/raw/claude/` - Text samples from Claude
   - `data/raw/llama/` - Text samples from LLaMA

2. Run the dataset creation script:
   ```bash
   python src/create_dataset.py --input data/raw --output data/test_samples.csv
   ```
   
   Parameters:
   - `--input`: Directory containing author subdirectories with text files
   - `--output`: Path to save the CSV dataset

### 6.2 Training Models

#### Quick Training (Single Random Forest Model)

```bash
python src/create_sample_model.py
```

This creates a simple Random Forest classifier and saves it to `models/stylometric/random_forest.pkl`.

#### Comprehensive Training (Multiple Models)

```bash
python src/train_models.py
```

This trains multiple models (Logistic Regression, Random Forest, Neural Network) using both stylometric features and transformer embeddings, then:
- Saves models to `models/stylometric/` and `models/combined/`
- Generates evaluation plots and metrics in `results/stylometric/` and `results/combined/`
- Performs hyperparameter tuning on the best model

### 6.3 Evaluating Models on New Data

```bash
python src/evaluate_model.py --model models/stylometric/random_forest.pkl --data data/test_samples.csv --output results/evaluation
```

Parameters:
- `--model`: Path to the trained model file (.pkl)
- `--data`: Path to the CSV file containing data (must have 'text' and 'label' columns)
- `--output`: Directory to save evaluation results

## 7. Features and Models Explained

### 7.1 Stylometric Features

The system extracts the following stylometric features from text:
- Text length (word count, character count)
- Average word length
- Punctuation usage (commas, semicolons, question marks, etc.)
- Sentence length statistics (average, standard deviation)
- Lexical diversity (unique words / total words)
- Capitalization patterns

### 7.2 Transformer Embeddings (Optional)

When training with the full pipeline, the system can also extract:
- RoBERTa embeddings (768-dimensional vector)
- XLNet embeddings (768-dimensional vector)

### 7.3 Classification Models

The system trains and compares these models:
- Logistic Regression
- Random Forest
- Neural Network (MLP Classifier)

## 8. Output and Results

### 8.1 Evaluation Metrics

After evaluating a model, you'll find these files in the output directory:

- `classification_report.txt`: Precision, recall, F1-score for each class
- `confusion_matrix.png`: Visualization of the confusion matrix
- `predictions.csv`: Detailed predictions for each sample

### 8.2 Interpreting Results

The classification report shows:
- **Precision**: How many selected items are relevant
- **Recall**: How many relevant items are selected
- **F1-score**: Harmonic mean of precision and recall
- **Support**: Number of samples for each class

The confusion matrix visualizes:
- True positives (diagonal)
- False positives/negatives (off-diagonal)

## 9. Example Workflow

1. Place text samples in appropriate directories
2. Create the dataset:
   ```bash
   python src/create_dataset.py
   ```
3. Train a model:
   ```bash
   python src/create_sample_model.py
   ```
4. Evaluate on new data:
   ```bash
   python src/evaluate_model.py --model models/stylometric/random_forest.pkl --data data/new_samples.csv
   ```
5. Analyze results in the `results/evaluation/` directory

## 10. Limitations and Considerations

- The system's accuracy depends on the quality and quantity of training data
- Longer text samples generally yield better results than very short ones
- Models trained on specific AI systems may not generalize well to new systems
- Performance may vary across different domains and topics
- For best results, train on text from the same domain as your evaluation data

## 11. Troubleshooting

- If NLTK resources are missing, the system will use a fallback for sentence tokenization
- Check that your CSV files have the required 'text' and 'label' columns
- Ensure your model was trained with the same feature set you're using for evaluation

## 12. References

This implementation is inspired by the work of Uchendu et al. in their paper "Authorship Attribution for Neural Text Generation" and their repository:
https://github.com/AdaUchendu/Authorship-Attribution-for-Neural-Text-Generation