Discussion:

Our experiments demonstrate that tree-based ensemble models (XGBoost, LightGBM, Stacking) substantially outperform neural networks on stylometric and RoBERTa PCA features for this dataset. The best ensemble (Stacking) achieves a mean accuracy of 0.95, while the best neural network achieves only 0.63, even after extensive hyperparameter tuning and feature selection. Feature selection did not improve neural network performance. These results are consistent with the literature: for small, tabular, mixed-type datasets, tree models are typically superior to neural networks unless the dataset is much larger or the features are specifically engineered for deep learning. We recommend ensemble tree models as the most robust and accurate approach for stylometric authorship/text classification in similar settings.
